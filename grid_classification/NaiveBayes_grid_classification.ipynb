{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "560e9332-b3c7-4d6a-8955-881a5d5feae5",
   "metadata": {},
   "source": [
    "## Naive bayes with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "111d9dd7-4b48-462f-b0b8-e5d81e326c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the dataset\n",
    "import pandas as pd \n",
    "dataset = pd.read_csv(\"Social_Network_Ads.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be1355c7-3081-4f49-a31d-2cf2c492e8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  EstimatedSalary  Purchased  Gender_Male\n",
       "0   19            19000          0            1\n",
       "1   35            20000          0            1\n",
       "2   26            43000          0            0\n",
       "3   27            57000          0            0\n",
       "4   19            76000          0            1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert categorical into numerical \n",
    "dataset = pd.get_dummies(dataset, drop_first=True, dtype=int)\n",
    "dataset = dataset.drop([\"User ID\"],axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a28439b0-52d4-4aa6-bcf0-7f47c6b2ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split input and output \n",
    "independent = dataset[[ \"Age\",\t\"EstimatedSalary\", \"Gender_Male\"]]\n",
    "dependent = dataset[[ \"Purchased\" ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bd61b89-da54-4e9f-8b32-a83b9ec63399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Purchased\n",
       "0    257\n",
       "1    143\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataset balance or imbalance\n",
    "dataset[\"Purchased\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88453cfd-3b56-4356-aba5-1446859616c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  EstimatedSalary  Gender_Male\n",
      "336   58           144000            1\n",
      "64    59            83000            0\n",
      "55    24            55000            0\n",
      "106   26            35000            0\n",
      "300   58            38000            0\n",
      "..   ...              ...          ...\n",
      "323   48            30000            0\n",
      "192   29            43000            1\n",
      "117   36            52000            1\n",
      "47    27            54000            0\n",
      "172   26           118000            0\n",
      "\n",
      "[320 rows x 3 columns]      Age  EstimatedSalary  Gender_Male\n",
      "132   30            87000            1\n",
      "309   38            50000            0\n",
      "341   35            75000            1\n",
      "196   30            79000            0\n",
      "246   35            50000            0\n",
      "..   ...              ...          ...\n",
      "14    18            82000            1\n",
      "363   42            79000            0\n",
      "304   40            60000            0\n",
      "361   53            34000            0\n",
      "329   47           107000            0\n",
      "\n",
      "[80 rows x 3 columns]      Purchased\n",
      "336          1\n",
      "64           0\n",
      "55           0\n",
      "106          0\n",
      "300          1\n",
      "..         ...\n",
      "323          1\n",
      "192          0\n",
      "117          0\n",
      "47           0\n",
      "172          0\n",
      "\n",
      "[320 rows x 1 columns]      Purchased\n",
      "132          0\n",
      "309          0\n",
      "341          0\n",
      "196          0\n",
      "246          0\n",
      "..         ...\n",
      "14           0\n",
      "363          0\n",
      "304          0\n",
      "361          1\n",
      "329          1\n",
      "\n",
      "[80 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# split train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(independent,dependent, test_size=0.20,random_state=0)\n",
    "print(x_train,x_test,y_train,y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83b6dd79-679d-48f6-a991-2b1f7cb15565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdfed5f5-ac40-493b-b431-ac70592f47b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abe98d5-1f17-40d0-b887-370c19070d56",
   "metadata": {},
   "source": [
    "## BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5281f50-725b-4d70-b227-c1d8cf7213d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "grid_prediction:  [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 1\n",
      " 1 0 0 0 1 1]\n",
      "cm:  [[51  7]\n",
      " [ 1 21]]\n",
      "clf_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93        58\n",
      "           1       0.75      0.95      0.84        22\n",
      "\n",
      "    accuracy                           0.90        80\n",
      "   macro avg       0.87      0.92      0.88        80\n",
      "weighted avg       0.92      0.90      0.90        80\n",
      "\n",
      "roc_auc_score:  0.9502351097178684\n",
      "f1_score:  0.9032727272727273\n",
      "grid_results:  {'mean_fit_time': array([0.05938811, 0.00636268, 0.0090117 , 0.00713673, 0.00581217,\n",
      "       0.007376  , 0.00557418, 0.00692739, 0.00668287]), 'std_fit_time': array([0.05767814, 0.0027178 , 0.00310171, 0.00214016, 0.00103258,\n",
      "       0.00141454, 0.00021549, 0.00151853, 0.00226406]), 'mean_score_time': array([0.0114459 , 0.0158915 , 0.01574926, 0.01192842, 0.01420445,\n",
      "       0.01327076, 0.00948787, 0.00981064, 0.01028514]), 'std_score_time': array([0.00247014, 0.00213966, 0.00713562, 0.00329362, 0.00307194,\n",
      "       0.0024386 , 0.00101604, 0.00137636, 0.00133423]), 'param_alpha': masked_array(data=[0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value=1e+20), 'param_binarize': masked_array(data=[0.0, 0.5, 1.0, 0.0, 0.5, 1.0, 0.0, 0.5, 1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value=1e+20), 'params': [{'alpha': 0.1, 'binarize': 0.0}, {'alpha': 0.1, 'binarize': 0.5}, {'alpha': 0.1, 'binarize': 1.0}, {'alpha': 0.5, 'binarize': 0.0}, {'alpha': 0.5, 'binarize': 0.5}, {'alpha': 0.5, 'binarize': 1.0}, {'alpha': 1.0, 'binarize': 0.0}, {'alpha': 1.0, 'binarize': 0.5}, {'alpha': 1.0, 'binarize': 1.0}], 'split0_test_score': array([0.73525433, 0.84561012, 0.78870554, 0.73525433, 0.84561012,\n",
      "       0.78870554, 0.73525433, 0.84561012, 0.78870554]), 'split1_test_score': array([0.72238576, 0.84487179, 0.78770676, 0.72238576, 0.84487179,\n",
      "       0.78770676, 0.72238576, 0.84487179, 0.78770676]), 'split2_test_score': array([0.6375    , 0.89234122, 0.76931818, 0.6375    , 0.89234122,\n",
      "       0.76931818, 0.6375    , 0.89234122, 0.76931818]), 'split3_test_score': array([0.67045455, 0.89213836, 0.84225875, 0.67045455, 0.89213836,\n",
      "       0.84225875, 0.67045455, 0.89213836, 0.84225875]), 'split4_test_score': array([0.75504626, 0.98443555, 0.92068273, 0.75504626, 0.98443555,\n",
      "       0.92068273, 0.75504626, 0.98443555, 0.92068273]), 'mean_test_score': array([0.70412818, 0.89187941, 0.82173439, 0.70412818, 0.89187941,\n",
      "       0.82173439, 0.70412818, 0.89187941, 0.82173439]), 'std_test_score': array([0.04351564, 0.05082811, 0.05515119, 0.04351564, 0.05082811,\n",
      "       0.05515119, 0.04351564, 0.05082811, 0.05515119]), 'rank_test_score': array([7, 1, 4, 7, 1, 4, 7, 1, 4], dtype=int32)}\n",
      "grid_model.best_params_ :  {'alpha': 0.1, 'binarize': 0.5}\n",
      "grid_model.best_estimator_:   BernoulliNB(alpha=0.1, binarize=0.5)\n",
      "grid_model.best_score_  :   0.8918794090986294\n"
     ]
    }
   ],
   "source": [
    "# model creation + grid cv  BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "\n",
    "param_grid ={\n",
    "\"alpha\" : [0.1, 0.5, 1.0],\n",
    "\"binarize\" : [0.0, 0.5, 1.0]\n",
    "}\n",
    "model = BernoulliNB()\n",
    "\n",
    "grid_model = GridSearchCV(model, param_grid,cv=5, refit=True, verbose=3  , n_jobs =-1, scoring='f1_weighted') \n",
    "grid_model.fit(x_train,y_train)\n",
    "\n",
    "# model prediction + grid cv\n",
    "grid_prediction = grid_model.predict(x_test)\n",
    "print(\"grid_prediction: \",grid_prediction)\n",
    "\n",
    "# model evaluation --- Performance on the unseen TEST dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test,grid_prediction)\n",
    "clf_report = classification_report(y_test, grid_prediction)\n",
    "print(\"cm: \", cm)\n",
    "print(\"clf_report: \", clf_report)\n",
    "\n",
    "## ROC AUC \n",
    "from sklearn.metrics import roc_auc_score     # key metric for binary classification \n",
    "roc_auc_score = roc_auc_score(y_test,grid_model.predict_proba(x_test)[:,1] )\n",
    "print(\"roc_auc_score: \", roc_auc_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(y_test,grid_prediction, average='weighted' )\n",
    "print(\"f1_score: \", f1_score)\n",
    "\n",
    "\n",
    "# grid results \n",
    "grid_results = grid_model.cv_results_\n",
    "print(\"grid_results: \", grid_results)\n",
    "\n",
    "print(\"grid_model.best_params_ : \",grid_model.best_params_)\n",
    "print(\"grid_model.best_estimator_:  \",grid_model.best_estimator_)\n",
    "print(\"grid_model.best_score_  :  \", grid_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c654f-c84e-4313-a585-24be6530e395",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fcd6b1e-e89c-4398-90cb-4b80ad3c469d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "grid_prediction:  [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 1]\n",
      "cm:  [[56  2]\n",
      " [ 4 18]]\n",
      "clf_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        58\n",
      "           1       0.90      0.82      0.86        22\n",
      "\n",
      "    accuracy                           0.93        80\n",
      "   macro avg       0.92      0.89      0.90        80\n",
      "weighted avg       0.92      0.93      0.92        80\n",
      "\n",
      "roc_auc_score:  0.9827586206896552\n",
      "f1_score:  0.9238498789346247\n",
      "grid_results:  {'mean_fit_time': array([0.00366888, 0.00593066, 0.00552254, 0.00610523]), 'std_fit_time': array([0.00048491, 0.00208882, 0.00279764, 0.00248753]), 'mean_score_time': array([0.0129281 , 0.01437631, 0.00947065, 0.00988183]), 'std_score_time': array([0.00220437, 0.00319739, 0.000908  , 0.00207795]), 'param_var_smoothing': masked_array(data=[1e-09, 1e-08, 1e-07, 1e-06],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value=1e+20), 'params': [{'var_smoothing': 1e-09}, {'var_smoothing': 1e-08}, {'var_smoothing': 1e-07}, {'var_smoothing': 1e-06}], 'split0_test_score': array([0.85984053, 0.85984053, 0.85984053, 0.85984053]), 'split1_test_score': array([0.80844156, 0.80844156, 0.80844156, 0.80844156]), 'split2_test_score': array([0.8107105, 0.8107105, 0.8107105, 0.8107105]), 'split3_test_score': array([0.90625, 0.90625, 0.90625, 0.90625]), 'split4_test_score': array([0.96845175, 0.96845175, 0.96845175, 0.96845175]), 'mean_test_score': array([0.87073887, 0.87073887, 0.87073887, 0.87073887]), 'std_test_score': array([0.06068275, 0.06068275, 0.06068275, 0.06068275]), 'rank_test_score': array([1, 1, 1, 1], dtype=int32)}\n",
      "grid_model.best_params_ :  {'var_smoothing': 1e-09}\n",
      "grid_model.best_estimator_:   GaussianNB()\n",
      "grid_model.best_score_  :   0.8707388667411436\n"
     ]
    }
   ],
   "source": [
    "# model creation + grid cv  GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "param_grid ={\n",
    "\"var_smoothing\" : [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "}\n",
    "model = GaussianNB()\n",
    "\n",
    "grid_model = GridSearchCV(model, param_grid,cv=5, refit=True, verbose=3  , n_jobs =-1, scoring='f1_weighted') \n",
    "grid_model.fit(x_train,y_train)\n",
    "\n",
    "# model prediction + grid cv\n",
    "grid_prediction = grid_model.predict(x_test)\n",
    "print(\"grid_prediction: \",grid_prediction)\n",
    "\n",
    "# model evaluation --- Performance on the unseen TEST dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test,grid_prediction)\n",
    "clf_report = classification_report(y_test, grid_prediction)\n",
    "print(\"cm: \", cm)\n",
    "print(\"clf_report: \", clf_report)\n",
    "\n",
    "## ROC AUC \n",
    "from sklearn.metrics import roc_auc_score     # key metric for binary classification \n",
    "roc_auc_score = roc_auc_score(y_test,grid_model.predict_proba(x_test)[:,1] )\n",
    "print(\"roc_auc_score: \", roc_auc_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(y_test,grid_prediction, average='weighted' )\n",
    "print(\"f1_score: \", f1_score)\n",
    "\n",
    "\n",
    "# grid results \n",
    "grid_results = grid_model.cv_results_\n",
    "print(\"grid_results: \", grid_results)\n",
    "\n",
    "print(\"grid_model.best_params_ : \",grid_model.best_params_)\n",
    "print(\"grid_model.best_estimator_:  \",grid_model.best_estimator_)\n",
    "print(\"grid_model.best_score_  :  \", grid_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce669c5b-7362-445c-b301-1b78efbde354",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0583d277-aff5-4463-9426-1e85c7e3a9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 40 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n40 fits failed with the following error:\nTraceback (most recent call last):\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 762, in fit\n    self._count(X, Y)\n    ~~~~~~~~~~~^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 889, in _count\n    check_non_negative(X, \"MultinomialNB (input X)\")\n    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1827, in check_non_negative\n    raise ValueError(f\"Negative values in data passed to {whom}.\")\nValueError: Negative values in data passed to MultinomialNB (input X).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[0;32m     11\u001b[0m grid_model \u001b[38;5;241m=\u001b[39m GridSearchCV(model, param_grid,cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m  , n_jobs \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m---> 12\u001b[0m grid_model\u001b[38;5;241m.\u001b[39mfit(x_train,y_train)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# model prediction + grid cv\u001b[39;00m\n\u001b[0;32m     15\u001b[0m grid_prediction \u001b[38;5;241m=\u001b[39m grid_model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1001\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    995\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    996\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    997\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    999\u001b[0m     )\n\u001b[1;32m-> 1001\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:517\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    511\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    516\u001b[0m     )\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 40 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n40 fits failed with the following error:\nTraceback (most recent call last):\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 762, in fit\n    self._count(X, Y)\n    ~~~~~~~~~~~^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 889, in _count\n    check_non_negative(X, \"MultinomialNB (input X)\")\n    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1827, in check_non_negative\n    raise ValueError(f\"Negative values in data passed to {whom}.\")\nValueError: Negative values in data passed to MultinomialNB (input X).\n"
     ]
    }
   ],
   "source": [
    "# model creation + grid cv  MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "\n",
    "param_grid ={\n",
    "\"alpha\" :[0.1, 0.5, 1.0, 2.0],\n",
    "\"fit_prior\": [True, False]\n",
    "}\n",
    "model = MultinomialNB()\n",
    "\n",
    "grid_model = GridSearchCV(model, param_grid,cv=5, refit=True, verbose=3  , n_jobs =-1, scoring='f1_weighted') \n",
    "grid_model.fit(x_train,y_train)\n",
    "\n",
    "# model prediction + grid cv\n",
    "grid_prediction = grid_model.predict(x_test)\n",
    "print(\"grid_prediction: \",grid_prediction)\n",
    "\n",
    "# model evaluation --- Performance on the unseen TEST dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test,grid_prediction)\n",
    "clf_report = classification_report(y_test, grid_prediction)\n",
    "print(\"cm: \", cm)\n",
    "print(\"clf_report: \", clf_report)\n",
    "\n",
    "## ROC AUC \n",
    "from sklearn.metrics import roc_auc_score     # key metric for binary classification \n",
    "roc_auc_score = roc_auc_score(y_test,grid_model.predict_proba(x_test)[:,1] )\n",
    "print(\"roc_auc_score: \", roc_auc_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(y_test,grid_prediction, average='weighted' )\n",
    "print(\"f1_score: \", f1_score)\n",
    "\n",
    "\n",
    "# grid results \n",
    "grid_results = grid_model.cv_results_\n",
    "print(\"grid_results: \", grid_results)\n",
    "\n",
    "print(\"grid_model.best_params_ : \",grid_model.best_params_)\n",
    "print(\"grid_model.best_estimator_:  \",grid_model.best_estimator_)\n",
    "print(\"grid_model.best_score_  :  \", grid_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d398af-3360-4525-898b-65a408bd0efc",
   "metadata": {},
   "source": [
    "## CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16ddb3dc-3fbb-4ab9-bcf3-f37dc6d23d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 45 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1388, in fit\n    return super().fit(X, y, sample_weight=sample_weight)\n           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 735, in fit\n    X, y = self._check_X_y(X, y)\n           ~~~~~~~~~~~~~~~^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1463, in _check_X_y\n    check_non_negative(X, \"CategoricalNB (input X)\")\n    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1827, in check_non_negative\n    raise ValueError(f\"Negative values in data passed to {whom}.\")\nValueError: Negative values in data passed to CategoricalNB (input X).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m CategoricalNB()\n\u001b[0;32m     12\u001b[0m grid_model \u001b[38;5;241m=\u001b[39m GridSearchCV(model, param_grid,cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m  , n_jobs \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m---> 13\u001b[0m grid_model\u001b[38;5;241m.\u001b[39mfit(x_train,y_train)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# model prediction + grid cv\u001b[39;00m\n\u001b[0;32m     16\u001b[0m grid_prediction \u001b[38;5;241m=\u001b[39m grid_model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1001\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    995\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    996\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    997\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    999\u001b[0m     )\n\u001b[1;32m-> 1001\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:517\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    511\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    516\u001b[0m     )\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 45 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1388, in fit\n    return super().fit(X, y, sample_weight=sample_weight)\n           ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 735, in fit\n    X, y = self._check_X_y(X, y)\n           ~~~~~~~~~~~~~~~^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1463, in _check_X_y\n    check_non_negative(X, \"CategoricalNB (input X)\")\n    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1827, in check_non_negative\n    raise ValueError(f\"Negative values in data passed to {whom}.\")\nValueError: Negative values in data passed to CategoricalNB (input X).\n"
     ]
    }
   ],
   "source": [
    "# model creation + grid cv  CategoricalNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import CategoricalNB \n",
    "\n",
    "param_grid ={\n",
    "\"alpha\" :[0.1, 0.5, 1.0],\n",
    "\"min_categories\" :[None, 2, 5],\n",
    "\n",
    "}\n",
    "model = CategoricalNB()\n",
    "\n",
    "grid_model = GridSearchCV(model, param_grid,cv=5, refit=True, verbose=3  , n_jobs =-1, scoring='f1_weighted') \n",
    "grid_model.fit(x_train,y_train)\n",
    "\n",
    "# model prediction + grid cv\n",
    "grid_prediction = grid_model.predict(x_test)\n",
    "print(\"grid_prediction: \",grid_prediction)\n",
    "\n",
    "# model evaluation --- Performance on the unseen TEST dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test,grid_prediction)\n",
    "clf_report = classification_report(y_test, grid_prediction)\n",
    "print(\"cm: \", cm)\n",
    "print(\"clf_report: \", clf_report)\n",
    "\n",
    "## ROC AUC \n",
    "from sklearn.metrics import roc_auc_score     # key metric for binary classification \n",
    "roc_auc_score = roc_auc_score(y_test,grid_model.predict_proba(x_test)[:,1] )\n",
    "print(\"roc_auc_score: \", roc_auc_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(y_test,grid_prediction, average='weighted' )\n",
    "print(\"f1_score: \", f1_score)\n",
    "\n",
    "\n",
    "# grid results \n",
    "grid_results = grid_model.cv_results_\n",
    "print(\"grid_results: \", grid_results)\n",
    "\n",
    "print(\"grid_model.best_params_ : \",grid_model.best_params_)\n",
    "print(\"grid_model.best_estimator_:  \",grid_model.best_estimator_)\n",
    "print(\"grid_model.best_score_  :  \", grid_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771ab2dc-8391-47a6-adb1-a814aacfdd51",
   "metadata": {},
   "source": [
    "## ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0be0d872-d2df-440d-8c4b-5560486950c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 30 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n30 fits failed with the following error:\nTraceback (most recent call last):\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 762, in fit\n    self._count(X, Y)\n    ~~~~~~~~~~~^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1037, in _count\n    check_non_negative(X, \"ComplementNB (input X)\")\n    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1827, in check_non_negative\n    raise ValueError(f\"Negative values in data passed to {whom}.\")\nValueError: Negative values in data passed to ComplementNB (input X).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m ComplementNB()\n\u001b[0;32m     11\u001b[0m grid_model \u001b[38;5;241m=\u001b[39m GridSearchCV(model, param_grid,cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m  , n_jobs \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m---> 12\u001b[0m grid_model\u001b[38;5;241m.\u001b[39mfit(x_train,y_train)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# model prediction + grid cv\u001b[39;00m\n\u001b[0;32m     15\u001b[0m grid_prediction \u001b[38;5;241m=\u001b[39m grid_model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1001\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    995\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    996\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    997\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    999\u001b[0m     )\n\u001b[1;32m-> 1001\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mE:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:517\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    511\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    516\u001b[0m     )\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 30 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n30 fits failed with the following error:\nTraceback (most recent call last):\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 762, in fit\n    self._count(X, Y)\n    ~~~~~~~~~~~^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1037, in _count\n    check_non_negative(X, \"ComplementNB (input X)\")\n    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1827, in check_non_negative\n    raise ValueError(f\"Negative values in data passed to {whom}.\")\nValueError: Negative values in data passed to ComplementNB (input X).\n"
     ]
    }
   ],
   "source": [
    "# model creation + grid cv  ComplementNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import ComplementNB \n",
    "\n",
    "param_grid ={\n",
    "\"alpha\" : [0.1, 0.5, 1.0],\n",
    "\"norm\" : [True, False]\n",
    "}\n",
    "model = ComplementNB()\n",
    "\n",
    "grid_model = GridSearchCV(model, param_grid,cv=5, refit=True, verbose=3  , n_jobs =-1, scoring='f1_weighted') \n",
    "grid_model.fit(x_train,y_train)\n",
    "\n",
    "# model prediction + grid cv\n",
    "grid_prediction = grid_model.predict(x_test)\n",
    "print(\"grid_prediction: \",grid_prediction)\n",
    "\n",
    "# model evaluation --- Performance on the unseen TEST dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test,grid_prediction)\n",
    "clf_report = classification_report(y_test, grid_prediction)\n",
    "print(\"cm: \", cm)\n",
    "print(\"clf_report: \", clf_report)\n",
    "\n",
    "## ROC AUC \n",
    "from sklearn.metrics import roc_auc_score     # key metric for binary classification \n",
    "roc_auc_score = roc_auc_score(y_test,grid_model.predict_proba(x_test)[:,1] )\n",
    "print(\"roc_auc_score: \", roc_auc_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(y_test,grid_prediction, average='weighted' )\n",
    "print(\"f1_score: \", f1_score)\n",
    "\n",
    "\n",
    "# grid results \n",
    "grid_results = grid_model.cv_results_\n",
    "print(\"grid_results: \", grid_results)\n",
    "\n",
    "print(\"grid_model.best_params_ : \",grid_model.best_params_)\n",
    "print(\"grid_model.best_estimator_:  \",grid_model.best_estimator_)\n",
    "print(\"grid_model.best_score_  :  \", grid_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2841410-7658-4a49-b437-5525d33cd620",
   "metadata": {},
   "source": [
    "## model prediction with real time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e16796ec-7607-4d1f-8568-9ee9be2a671a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your gender (0-female/1-male):  1\n",
      "Enter your age:  36\n",
      "Enter your estimated salary:  33000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" test input data's\\nMale\\t19\\t19000\\t- 0\\nFemale\\t46\\t41000\\t- 1\\nFemale\\t50\\t20000\\t- 1\\nMale\\t36\\t33000\\t- 0\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## user input \n",
    "Gender=int(input(\"Enter your gender (0-female/1-male): \"))\n",
    "Age\t= int(input(\"Enter your age: \"))\n",
    "EstimatedSalary = int(input(\"Enter your estimated salary: \"))\n",
    "\n",
    "\n",
    "\"\"\" test input data's\n",
    "Male\t19\t19000\t- 0\n",
    "Female\t46\t41000\t- 1\n",
    "Female\t50\t20000\t- 1\n",
    "Male\t36\t33000\t- 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "671046fb-53b8-4531-b5c7-85247bccc43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user will purchase\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "## user input predction \n",
    "user_input_prediction = grid_model.predict([[Gender,Age,EstimatedSalary ]])\n",
    "if user_input_prediction==1:\n",
    "    print(\"user will purchase\")\n",
    "else:\n",
    "    print(\"user will not purchase\")\n",
    "\n",
    "print(user_input_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
