{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "560e9332-b3c7-4d6a-8955-881a5d5feae5",
   "metadata": {},
   "source": [
    "## Naive bayes with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "111d9dd7-4b48-462f-b0b8-e5d81e326c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the dataset\n",
    "import pandas as pd \n",
    "dataset = pd.read_csv(\"Social_Network_Ads.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "be1355c7-3081-4f49-a31d-2cf2c492e8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  EstimatedSalary  Purchased  Gender_Male\n",
       "0   19            19000          0            1\n",
       "1   35            20000          0            1\n",
       "2   26            43000          0            0\n",
       "3   27            57000          0            0\n",
       "4   19            76000          0            1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert categorical into numerical \n",
    "dataset = pd.get_dummies(dataset, drop_first=True, dtype=int)\n",
    "dataset = dataset.drop([\"User ID\"],axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a28439b0-52d4-4aa6-bcf0-7f47c6b2ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split input and output \n",
    "independent = dataset[[ \"Age\",\t\"EstimatedSalary\", \"Gender_Male\"]]\n",
    "dependent = dataset[[ \"Purchased\" ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5bd61b89-da54-4e9f-8b32-a83b9ec63399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Purchased\n",
       "0    257\n",
       "1    143\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataset balance or imbalance\n",
    "dataset[\"Purchased\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "88453cfd-3b56-4356-aba5-1446859616c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  EstimatedSalary  Gender_Male\n",
      "336   58           144000            1\n",
      "64    59            83000            0\n",
      "55    24            55000            0\n",
      "106   26            35000            0\n",
      "300   58            38000            0\n",
      "..   ...              ...          ...\n",
      "323   48            30000            0\n",
      "192   29            43000            1\n",
      "117   36            52000            1\n",
      "47    27            54000            0\n",
      "172   26           118000            0\n",
      "\n",
      "[320 rows x 3 columns]      Age  EstimatedSalary  Gender_Male\n",
      "132   30            87000            1\n",
      "309   38            50000            0\n",
      "341   35            75000            1\n",
      "196   30            79000            0\n",
      "246   35            50000            0\n",
      "..   ...              ...          ...\n",
      "14    18            82000            1\n",
      "363   42            79000            0\n",
      "304   40            60000            0\n",
      "361   53            34000            0\n",
      "329   47           107000            0\n",
      "\n",
      "[80 rows x 3 columns]      Purchased\n",
      "336          1\n",
      "64           0\n",
      "55           0\n",
      "106          0\n",
      "300          1\n",
      "..         ...\n",
      "323          1\n",
      "192          0\n",
      "117          0\n",
      "47           0\n",
      "172          0\n",
      "\n",
      "[320 rows x 1 columns]      Purchased\n",
      "132          0\n",
      "309          0\n",
      "341          0\n",
      "196          0\n",
      "246          0\n",
      "..         ...\n",
      "14           0\n",
      "363          0\n",
      "304          0\n",
      "361          1\n",
      "329          1\n",
      "\n",
      "[80 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# split train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(independent,dependent, test_size=0.20,random_state=0)\n",
    "print(x_train,x_test,y_train,y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bdfed5f5-ac40-493b-b431-ac70592f47b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce669c5b-7362-445c-b301-1b78efbde354",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0583d277-aff5-4463-9426-1e85c7e3a9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "grid_prediction:  [0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1\n",
      " 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0\n",
      " 1 1 0 0 0 1]\n",
      "cm:  [[37 21]\n",
      " [13  9]]\n",
      "clf_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.64      0.69        58\n",
      "           1       0.30      0.41      0.35        22\n",
      "\n",
      "    accuracy                           0.57        80\n",
      "   macro avg       0.52      0.52      0.52        80\n",
      "weighted avg       0.62      0.57      0.59        80\n",
      "\n",
      "roc_auc_score:  0.48824451410658304\n",
      "f1_score:  0.5919515669515669\n",
      "grid_results:  {'mean_fit_time': array([0.03456964, 0.01253185, 0.01661758, 0.01292815, 0.01345854,\n",
      "       0.01409421, 0.01167436, 0.0177598 ]), 'std_fit_time': array([0.02931945, 0.00266501, 0.0070475 , 0.00610893, 0.00338532,\n",
      "       0.00840889, 0.00314421, 0.00736478]), 'mean_score_time': array([0.02241397, 0.01589155, 0.01318059, 0.01442385, 0.01321898,\n",
      "       0.01416883, 0.01302395, 0.01342201]), 'std_score_time': array([0.00950329, 0.00163212, 0.0013244 , 0.00191769, 0.00269973,\n",
      "       0.00129766, 0.0031942 , 0.00234323]), 'param_alpha': masked_array(data=[0.1, 0.1, 0.5, 0.5, 1.0, 1.0, 2.0, 2.0],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value=1e+20), 'param_fit_prior': masked_array(data=[True, False, True, False, True, False, True, False],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value=True), 'params': [{'alpha': 0.1, 'fit_prior': True}, {'alpha': 0.1, 'fit_prior': False}, {'alpha': 0.5, 'fit_prior': True}, {'alpha': 0.5, 'fit_prior': False}, {'alpha': 1.0, 'fit_prior': True}, {'alpha': 1.0, 'fit_prior': False}, {'alpha': 2.0, 'fit_prior': True}, {'alpha': 2.0, 'fit_prior': False}], 'split0_test_score': array([0.62802419, 0.53679187, 0.62802419, 0.53679187, 0.62802419,\n",
      "       0.53679187, 0.62802419, 0.55236132]), 'split1_test_score': array([0.65706476, 0.47238514, 0.65706476, 0.47238514, 0.65706476,\n",
      "       0.47238514, 0.65706476, 0.47238514]), 'split2_test_score': array([0.63030096, 0.53694332, 0.63030096, 0.53694332, 0.63030096,\n",
      "       0.52232704, 0.63030096, 0.52232704]), 'split3_test_score': array([0.68388073, 0.62955466, 0.68388073, 0.62955466, 0.68388073,\n",
      "       0.62955466, 0.68388073, 0.62955466]), 'split4_test_score': array([0.6375    , 0.56781377, 0.6375    , 0.56781377, 0.6375    ,\n",
      "       0.56781377, 0.6375    , 0.56781377]), 'mean_test_score': array([0.64735413, 0.54869775, 0.64735413, 0.54869775, 0.64735413,\n",
      "       0.5457745 , 0.64735413, 0.54888838]), 'std_test_score': array([0.02092869, 0.05100351, 0.02092869, 0.05100351, 0.02092869,\n",
      "       0.05200252, 0.02092869, 0.0518373 ]), 'rank_test_score': array([1, 6, 1, 6, 1, 8, 1, 5], dtype=int32)}\n",
      "grid_model.best_params_ :  {'alpha': 0.1, 'fit_prior': True}\n",
      "grid_model.best_estimator_:   MultinomialNB(alpha=0.1)\n",
      "grid_model.best_score_  :   0.647354127491812\n"
     ]
    }
   ],
   "source": [
    "# model creation + grid cv  MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "\n",
    "param_grid ={\n",
    "\"alpha\" :[0.1, 0.5, 1.0, 2.0],\n",
    "\"fit_prior\": [True, False]\n",
    "}\n",
    "model = MultinomialNB()\n",
    "\n",
    "grid_model = GridSearchCV(model, param_grid,cv=5, refit=True, verbose=3  , n_jobs =-1, scoring='f1_weighted') \n",
    "grid_model.fit(x_train,y_train)\n",
    "\n",
    "# model prediction + grid cv\n",
    "grid_prediction = grid_model.predict(x_test)\n",
    "print(\"grid_prediction: \",grid_prediction)\n",
    "\n",
    "# model evaluation --- Performance on the unseen TEST dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test,grid_prediction)\n",
    "clf_report = classification_report(y_test, grid_prediction)\n",
    "print(\"cm: \", cm)\n",
    "print(\"clf_report: \", clf_report)\n",
    "\n",
    "## ROC AUC \n",
    "from sklearn.metrics import roc_auc_score     # key metric for binary classification \n",
    "roc_auc_score = roc_auc_score(y_test,grid_model.predict_proba(x_test)[:,1] )\n",
    "print(\"roc_auc_score: \", roc_auc_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(y_test,grid_prediction, average='weighted' )\n",
    "print(\"f1_score: \", f1_score)\n",
    "\n",
    "\n",
    "# grid results \n",
    "grid_results = grid_model.cv_results_\n",
    "print(\"grid_results: \", grid_results)\n",
    "\n",
    "print(\"grid_model.best_params_ : \",grid_model.best_params_)\n",
    "print(\"grid_model.best_estimator_:  \",grid_model.best_estimator_)\n",
    "print(\"grid_model.best_score_  :  \", grid_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d398af-3360-4525-898b-65a408bd0efc",
   "metadata": {},
   "source": [
    "## CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "16ddb3dc-3fbb-4ab9-bcf3-f37dc6d23d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_prediction:  [0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 1 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1\n",
      " 0 0 0 0 1 1]\n",
      "cm:  [[52  6]\n",
      " [ 4 18]]\n",
      "clf_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91        58\n",
      "           1       0.75      0.82      0.78        22\n",
      "\n",
      "    accuracy                           0.88        80\n",
      "   macro avg       0.84      0.86      0.85        80\n",
      "weighted avg       0.88      0.88      0.88        80\n",
      "\n",
      "roc_auc_score:  0.9149686520376177\n",
      "f1_score:  0.8766209000762777\n",
      "grid_results:  {'mean_fit_time': array([0.05582461, 0.05830116, 0.07547822, 0.06779914, 0.05148211,\n",
      "       0.06952777, 0.07338476, 0.0676115 , 0.07259007]), 'std_fit_time': array([0.00955131, 0.0143145 , 0.01084725, 0.00964969, 0.00439893,\n",
      "       0.00581673, 0.01088232, 0.01526651, 0.03315617]), 'mean_score_time': array([0.03284707, 0.02245874, 0.01791182, 0.01933918, 0.01774507,\n",
      "       0.02231193, 0.02215443, 0.01742058, 0.02046599]), 'std_score_time': array([0.03771024, 0.00993126, 0.00449533, 0.0035241 , 0.00749294,\n",
      "       0.00365831, 0.0068854 , 0.00336588, 0.00631451]), 'param_alpha': masked_array(data=[0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value=1e+20), 'param_min_categories': masked_array(data=[None, 2, 5, None, 2, 5, None, 2, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value=np.str_('?'),\n",
      "            dtype=object), 'params': [{'alpha': 0.1, 'min_categories': None}, {'alpha': 0.1, 'min_categories': 2}, {'alpha': 0.1, 'min_categories': 5}, {'alpha': 0.5, 'min_categories': None}, {'alpha': 0.5, 'min_categories': 2}, {'alpha': 0.5, 'min_categories': 5}, {'alpha': 1.0, 'min_categories': None}, {'alpha': 1.0, 'min_categories': 2}, {'alpha': 1.0, 'min_categories': 5}], 'split0_test_score': array([0.7770745, 0.7770745, 0.7770745, 0.8258225, 0.8258225, 0.8258225,\n",
      "       0.808921 , 0.808921 , 0.808921 ]), 'split1_test_score': array([0.76461988, 0.76461988, 0.76461988, 0.74495099, 0.74495099,\n",
      "       0.74495099, 0.72463768, 0.72463768, 0.72463768]), 'split2_test_score': array([0.72674419, 0.72674419, 0.72674419, 0.74086379, 0.74086379,\n",
      "       0.74086379, 0.72238576, 0.72238576, 0.73636364]), 'split3_test_score': array([0.77325581, 0.77325581, 0.77325581, 0.75504626, 0.75504626,\n",
      "       0.75504626, 0.80227273, 0.80227273, 0.80227273]), 'split4_test_score': array([nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'mean_test_score': array([nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'std_test_score': array([nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "grid_model.best_params_ :  {'alpha': 0.1, 'min_categories': None}\n",
      "grid_model.best_estimator_:   CategoricalNB(alpha=0.1)\n",
      "grid_model.best_score_  :   nan\n"
     ]
    }
   ],
   "source": [
    "# model creation + grid cv  CategoricalNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import CategoricalNB \n",
    "\n",
    "param_grid ={\n",
    "\"alpha\" :[0.1, 0.5, 1.0],\n",
    "\"min_categories\" :[None, 2, 5],\n",
    "\n",
    "}\n",
    "model = CategoricalNB()\n",
    "\n",
    "grid_model = GridSearchCV(model, param_grid,cv=5, refit=True, verbose=3  , n_jobs =-1, scoring='f1_weighted') \n",
    "grid_model.fit(x_train,y_train)\n",
    "\n",
    "# model prediction + grid cv\n",
    "grid_prediction = grid_model.predict(x_test)\n",
    "print(\"grid_prediction: \",grid_prediction)\n",
    "\n",
    "# model evaluation --- Performance on the unseen TEST dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test,grid_prediction)\n",
    "clf_report = classification_report(y_test, grid_prediction)\n",
    "print(\"cm: \", cm)\n",
    "print(\"clf_report: \", clf_report)\n",
    "\n",
    "## ROC AUC \n",
    "from sklearn.metrics import roc_auc_score     # key metric for binary classification \n",
    "roc_auc_score = roc_auc_score(y_test,grid_model.predict_proba(x_test)[:,1] )\n",
    "print(\"roc_auc_score: \", roc_auc_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(y_test,grid_prediction, average='weighted' )\n",
    "print(\"f1_score: \", f1_score)\n",
    "\n",
    "\n",
    "# grid results \n",
    "grid_results = grid_model.cv_results_\n",
    "print(\"grid_results: \", grid_results)\n",
    "\n",
    "print(\"grid_model.best_params_ : \",grid_model.best_params_)\n",
    "print(\"grid_model.best_estimator_:  \",grid_model.best_estimator_)\n",
    "print(\"grid_model.best_score_  :  \", grid_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771ab2dc-8391-47a6-adb1-a814aacfdd51",
   "metadata": {},
   "source": [
    "## ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0be0d872-d2df-440d-8c4b-5560486950c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "grid_prediction:  [1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1\n",
      " 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0\n",
      " 1 1 1 0 0 1]\n",
      "cm:  [[27 31]\n",
      " [10 12]]\n",
      "clf_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.47      0.57        58\n",
      "           1       0.28      0.55      0.37        22\n",
      "\n",
      "    accuracy                           0.49        80\n",
      "   macro avg       0.50      0.51      0.47        80\n",
      "weighted avg       0.61      0.49      0.51        80\n",
      "\n",
      "roc_auc_score:  0.48824451410658304\n",
      "f1_score:  0.5136437246963562\n",
      "grid_results:  {'mean_fit_time': array([0.02371101, 0.01645703, 0.01730247, 0.01908183, 0.01740894,\n",
      "       0.02121897]), 'std_fit_time': array([0.01701898, 0.01197934, 0.0130757 , 0.00637019, 0.00539416,\n",
      "       0.00647434]), 'mean_score_time': array([0.01411495, 0.0151792 , 0.02204318, 0.01913166, 0.01757336,\n",
      "       0.02159057]), 'std_score_time': array([0.00593572, 0.00126967, 0.01324066, 0.00646296, 0.00231466,\n",
      "       0.00328099]), 'param_alpha': masked_array(data=[0.1, 0.1, 0.5, 0.5, 1.0, 1.0],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value=1e+20), 'param_norm': masked_array(data=[True, False, True, False, True, False],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value=True), 'params': [{'alpha': 0.1, 'norm': True}, {'alpha': 0.1, 'norm': False}, {'alpha': 0.5, 'norm': True}, {'alpha': 0.5, 'norm': False}, {'alpha': 1.0, 'norm': True}, {'alpha': 1.0, 'norm': False}], 'split0_test_score': array([0.21945225, 0.53679187, 0.21945225, 0.53679187, 0.21945225,\n",
      "       0.53679187]), 'split1_test_score': array([0.20454545, 0.47238514, 0.20454545, 0.47238514, 0.20454545,\n",
      "       0.47238514]), 'split2_test_score': array([0.20454545, 0.53694332, 0.20454545, 0.53694332, 0.20454545,\n",
      "       0.52232704]), 'split3_test_score': array([0.20454545, 0.62955466, 0.20454545, 0.62955466, 0.20454545,\n",
      "       0.62955466]), 'split4_test_score': array([0.20454545, 0.56781377, 0.20454545, 0.56781377, 0.20454545,\n",
      "       0.56781377]), 'mean_test_score': array([0.20752681, 0.54869775, 0.20752681, 0.54869775, 0.20752681,\n",
      "       0.5457745 ]), 'std_test_score': array([0.00596272, 0.05100351, 0.00596272, 0.05100351, 0.00596272,\n",
      "       0.05200252]), 'rank_test_score': array([4, 1, 4, 1, 4, 3], dtype=int32)}\n",
      "grid_model.best_params_ :  {'alpha': 0.1, 'norm': False}\n",
      "grid_model.best_estimator_:   ComplementNB(alpha=0.1)\n",
      "grid_model.best_score_  :   0.5486977509103702\n"
     ]
    }
   ],
   "source": [
    "# model creation + grid cv  ComplementNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import ComplementNB \n",
    "\n",
    "param_grid ={\n",
    "\"alpha\" : [0.1, 0.5, 1.0],\n",
    "\"norm\" : [True, False]\n",
    "}\n",
    "model = ComplementNB()\n",
    "\n",
    "grid_model = GridSearchCV(model, param_grid,cv=5, refit=True, verbose=3  , n_jobs =-1, scoring='f1_weighted') \n",
    "grid_model.fit(x_train,y_train)\n",
    "\n",
    "# model prediction + grid cv\n",
    "grid_prediction = grid_model.predict(x_test)\n",
    "print(\"grid_prediction: \",grid_prediction)\n",
    "\n",
    "# model evaluation --- Performance on the unseen TEST dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test,grid_prediction)\n",
    "clf_report = classification_report(y_test, grid_prediction)\n",
    "print(\"cm: \", cm)\n",
    "print(\"clf_report: \", clf_report)\n",
    "\n",
    "## ROC AUC \n",
    "from sklearn.metrics import roc_auc_score     # key metric for binary classification \n",
    "roc_auc_score = roc_auc_score(y_test,grid_model.predict_proba(x_test)[:,1] )\n",
    "print(\"roc_auc_score: \", roc_auc_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(y_test,grid_prediction, average='weighted' )\n",
    "print(\"f1_score: \", f1_score)\n",
    "\n",
    "\n",
    "# grid results \n",
    "grid_results = grid_model.cv_results_\n",
    "print(\"grid_results: \", grid_results)\n",
    "\n",
    "print(\"grid_model.best_params_ : \",grid_model.best_params_)\n",
    "print(\"grid_model.best_estimator_:  \",grid_model.best_estimator_)\n",
    "print(\"grid_model.best_score_  :  \", grid_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "83b6dd79-679d-48f6-a991-2b1f7cb15565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abe98d5-1f17-40d0-b887-370c19070d56",
   "metadata": {},
   "source": [
    "## BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c5281f50-725b-4d70-b227-c1d8cf7213d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "grid_prediction:  [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 1 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 1\n",
      " 1 0 0 0 1 1]\n",
      "cm:  [[51  7]\n",
      " [ 1 21]]\n",
      "clf_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93        58\n",
      "           1       0.75      0.95      0.84        22\n",
      "\n",
      "    accuracy                           0.90        80\n",
      "   macro avg       0.87      0.92      0.88        80\n",
      "weighted avg       0.92      0.90      0.90        80\n",
      "\n",
      "roc_auc_score:  0.9502351097178684\n",
      "f1_score:  0.9032727272727273\n",
      "grid_results:  {'mean_fit_time': array([0.17053394, 0.00854344, 0.00589814, 0.00583034, 0.00820489,\n",
      "       0.005756  , 0.00635471, 0.00627542, 0.00763063]), 'std_fit_time': array([0.19417104, 0.00337104, 0.00198769, 0.00095278, 0.00247264,\n",
      "       0.00132182, 0.00249179, 0.00174821, 0.00261252]), 'mean_score_time': array([0.01251802, 0.0132823 , 0.01360698, 0.01378808, 0.0137588 ,\n",
      "       0.01327434, 0.01081295, 0.01180239, 0.01248794]), 'std_score_time': array([0.00378183, 0.00294767, 0.00293377, 0.00413669, 0.00331611,\n",
      "       0.00529107, 0.00162239, 0.00365707, 0.00308158]), 'param_alpha': masked_array(data=[0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value=1e+20), 'param_binarize': masked_array(data=[0.0, 0.5, 1.0, 0.0, 0.5, 1.0, 0.0, 0.5, 1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value=1e+20), 'params': [{'alpha': 0.1, 'binarize': 0.0}, {'alpha': 0.1, 'binarize': 0.5}, {'alpha': 0.1, 'binarize': 1.0}, {'alpha': 0.5, 'binarize': 0.0}, {'alpha': 0.5, 'binarize': 0.5}, {'alpha': 0.5, 'binarize': 1.0}, {'alpha': 1.0, 'binarize': 0.0}, {'alpha': 1.0, 'binarize': 0.5}, {'alpha': 1.0, 'binarize': 1.0}], 'split0_test_score': array([0.73525433, 0.84561012, 0.78870554, 0.73525433, 0.84561012,\n",
      "       0.78870554, 0.73525433, 0.84561012, 0.78870554]), 'split1_test_score': array([0.72238576, 0.84487179, 0.78770676, 0.72238576, 0.84487179,\n",
      "       0.78770676, 0.72238576, 0.84487179, 0.78770676]), 'split2_test_score': array([0.6375    , 0.89234122, 0.76931818, 0.6375    , 0.89234122,\n",
      "       0.76931818, 0.6375    , 0.89234122, 0.76931818]), 'split3_test_score': array([0.67045455, 0.89213836, 0.84225875, 0.67045455, 0.89213836,\n",
      "       0.84225875, 0.67045455, 0.89213836, 0.84225875]), 'split4_test_score': array([0.75504626, 0.98443555, 0.92068273, 0.75504626, 0.98443555,\n",
      "       0.92068273, 0.75504626, 0.98443555, 0.92068273]), 'mean_test_score': array([0.70412818, 0.89187941, 0.82173439, 0.70412818, 0.89187941,\n",
      "       0.82173439, 0.70412818, 0.89187941, 0.82173439]), 'std_test_score': array([0.04351564, 0.05082811, 0.05515119, 0.04351564, 0.05082811,\n",
      "       0.05515119, 0.04351564, 0.05082811, 0.05515119]), 'rank_test_score': array([7, 1, 4, 7, 1, 4, 7, 1, 4], dtype=int32)}\n",
      "grid_model.best_params_ :  {'alpha': 0.1, 'binarize': 0.5}\n",
      "grid_model.best_estimator_:   BernoulliNB(alpha=0.1, binarize=0.5)\n",
      "grid_model.best_score_  :   0.8918794090986294\n"
     ]
    }
   ],
   "source": [
    "# model creation + grid cv  BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "\n",
    "param_grid ={\n",
    "\"alpha\" : [0.1, 0.5, 1.0],\n",
    "\"binarize\" : [0.0, 0.5, 1.0]\n",
    "}\n",
    "model = BernoulliNB()\n",
    "\n",
    "grid_model_BernoulliNB = GridSearchCV(model, param_grid,cv=5, refit=True, verbose=3  , n_jobs =-1, scoring='f1_weighted') \n",
    "grid_model_BernoulliNB.fit(x_train,y_train)\n",
    "\n",
    "# model prediction + grid cv\n",
    "grid_prediction = grid_model_BernoulliNB.predict(x_test)\n",
    "print(\"grid_prediction: \",grid_prediction)\n",
    "\n",
    "# model evaluation --- Performance on the unseen TEST dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test,grid_prediction)\n",
    "clf_report = classification_report(y_test, grid_prediction)\n",
    "print(\"cm: \", cm)\n",
    "print(\"clf_report: \", clf_report)\n",
    "\n",
    "## ROC AUC \n",
    "from sklearn.metrics import roc_auc_score     # key metric for binary classification \n",
    "roc_auc_score = roc_auc_score(y_test,grid_model_BernoulliNB.predict_proba(x_test)[:,1] )\n",
    "print(\"roc_auc_score: \", roc_auc_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(y_test,grid_prediction, average='weighted' )\n",
    "print(\"f1_score: \", f1_score)\n",
    "\n",
    "\n",
    "# grid results \n",
    "grid_results = grid_model_BernoulliNB.cv_results_\n",
    "print(\"grid_results: \", grid_results)\n",
    "\n",
    "print(\"grid_model.best_params_ : \",grid_model_BernoulliNB.best_params_)\n",
    "print(\"grid_model.best_estimator_:  \",grid_model_BernoulliNB.best_estimator_)\n",
    "print(\"grid_model.best_score_  :  \", grid_model_BernoulliNB.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c654f-c84e-4313-a585-24be6530e395",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fcd6b1e-e89c-4398-90cb-4b80ad3c469d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "grid_prediction:  [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 1]\n",
      "cm:  [[56  2]\n",
      " [ 4 18]]\n",
      "clf_report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        58\n",
      "           1       0.90      0.82      0.86        22\n",
      "\n",
      "    accuracy                           0.93        80\n",
      "   macro avg       0.92      0.89      0.90        80\n",
      "weighted avg       0.92      0.93      0.92        80\n",
      "\n",
      "roc_auc_score:  0.9827586206896552\n",
      "f1_score:  0.9238498789346247\n",
      "grid_results:  {'mean_fit_time': array([0.00416136, 0.00517302, 0.0050528 , 0.00471735]), 'std_fit_time': array([0.00091522, 0.00134381, 0.00177974, 0.00129401]), 'mean_score_time': array([0.00921645, 0.01020894, 0.00851207, 0.00962462]), 'std_score_time': array([0.00121252, 0.00199239, 0.00079427, 0.00119536]), 'param_var_smoothing': masked_array(data=[1e-09, 1e-08, 1e-07, 1e-06],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value=1e+20), 'params': [{'var_smoothing': 1e-09}, {'var_smoothing': 1e-08}, {'var_smoothing': 1e-07}, {'var_smoothing': 1e-06}], 'split0_test_score': array([0.85984053, 0.85984053, 0.85984053, 0.85984053]), 'split1_test_score': array([0.80844156, 0.80844156, 0.80844156, 0.80844156]), 'split2_test_score': array([0.8107105, 0.8107105, 0.8107105, 0.8107105]), 'split3_test_score': array([0.90625, 0.90625, 0.90625, 0.90625]), 'split4_test_score': array([0.96845175, 0.96845175, 0.96845175, 0.96845175]), 'mean_test_score': array([0.87073887, 0.87073887, 0.87073887, 0.87073887]), 'std_test_score': array([0.06068275, 0.06068275, 0.06068275, 0.06068275]), 'rank_test_score': array([1, 1, 1, 1], dtype=int32)}\n",
      "grid_model.best_params_ :  {'var_smoothing': 1e-09}\n",
      "grid_model.best_estimator_:   GaussianNB()\n",
      "grid_model.best_score_  :   0.8707388667411436\n"
     ]
    }
   ],
   "source": [
    "# model creation + grid cv  GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "param_grid ={\n",
    "\"var_smoothing\" : [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "}\n",
    "model = GaussianNB()\n",
    "\n",
    "grid_model_GaussianNB = GridSearchCV(model, param_grid,cv=5, refit=True, verbose=3  , n_jobs =-1, scoring='f1_weighted') \n",
    "grid_model_GaussianNB.fit(x_train,y_train)\n",
    "\n",
    "# model prediction + grid cv\n",
    "grid_prediction = grid_model_GaussianNB.predict(x_test)\n",
    "print(\"grid_prediction: \",grid_prediction)\n",
    "\n",
    "# model evaluation --- Performance on the unseen TEST dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test,grid_prediction)\n",
    "clf_report = classification_report(y_test, grid_prediction)\n",
    "print(\"cm: \", cm)\n",
    "print(\"clf_report: \", clf_report)\n",
    "\n",
    "## ROC AUC \n",
    "from sklearn.metrics import roc_auc_score     # key metric for binary classification \n",
    "roc_auc_score = roc_auc_score(y_test,grid_model_GaussianNB.predict_proba(x_test)[:,1] )\n",
    "print(\"roc_auc_score: \", roc_auc_score)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(y_test,grid_prediction, average='weighted' )\n",
    "print(\"f1_score: \", f1_score)\n",
    "\n",
    "\n",
    "# grid results \n",
    "grid_results = grid_model_GaussianNB.cv_results_\n",
    "print(\"grid_results: \", grid_results)\n",
    "\n",
    "print(\"grid_model.best_params_ : \",grid_model_GaussianNB.best_params_)\n",
    "print(\"grid_model.best_estimator_:  \",grid_model_GaussianNB.best_estimator_)\n",
    "print(\"grid_model.best_score_  :  \", grid_model_GaussianNB.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a02caae-08e0-49cf-9772-5c1ec7f9de9a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2841410-7658-4a49-b437-5525d33cd620",
   "metadata": {},
   "source": [
    "## model prediction with real time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e16796ec-7607-4d1f-8568-9ee9be2a671a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your gender (0-female/1-male):  0\n",
      "Enter your age:  50\n",
      "Enter your estimated salary:  20000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" test input data's\\nMale\\t19\\t19000\\t- 0\\nFemale\\t46\\t41000\\t- 1\\nFemale\\t50\\t20000\\t- 1\\nMale\\t36\\t33000\\t- 0\\n\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## user input \n",
    "Gender=int(input(\"Enter your gender (0-female/1-male): \"))\n",
    "Age\t= int(input(\"Enter your age: \"))\n",
    "EstimatedSalary = int(input(\"Enter your estimated salary: \"))\n",
    "\n",
    "\n",
    "\"\"\" test input data's\n",
    "Male\t19\t19000\t- 0\n",
    "Female\t46\t41000\t- 1\n",
    "Female\t50\t20000\t- 1\n",
    "Male\t36\t33000\t- 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "671046fb-53b8-4531-b5c7-85247bccc43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user will not purchase\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "## user input predction \n",
    "user_input_prediction = grid_model_GaussianNB.predict([[Gender,Age,EstimatedSalary ]])\n",
    "if user_input_prediction==1:\n",
    "    print(\"user will purchase\")\n",
    "else:\n",
    "    print(\"user will not purchase\")\n",
    "\n",
    "print(user_input_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
